{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixtan/opt/anaconda3/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.linalg import norm\n",
    "import jieba\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "#特征提取\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#特征提取\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#保存模型\n",
    "import joblib\n",
    "import random\n",
    "from sklearn.cluster import DBSCAN\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建停用词list\n",
    "def readwordslist(filepath):\n",
    "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成中国城市区域名称\n",
    "def citynamesgenerator():\n",
    "    stopwords = readwordslist('./city.txt')  # 这里加载停用词的路径\n",
    "    file_write_obj = open(\"citynames.txt\", 'w',encoding='utf-8')\n",
    "    for word in stopwords:\n",
    "        cityname=word.split(' ')[1]\n",
    "        # 以写的方式打开文件，如果文件不存在，就会自动创建\n",
    "        file_write_obj.writelines(cityname)\n",
    "        file_write_obj.write('\\n')\n",
    "        # 清洗城市级别前缀\n",
    "        if cityname.endswith('特别行政区'): sub_cityname=cityname.rstrip('特别行政区')\n",
    "        elif cityname.endswith('市辖区'): sub_cityname=cityname.rstrip('市辖区')\n",
    "        elif cityname.endswith('省'): sub_cityname=cityname.rstrip('省')\n",
    "        elif cityname.endswith('市'): sub_cityname=cityname.rstrip('市')\n",
    "        else: sub_cityname=cityname\n",
    "        #.rstrip('区').rstrip('县').rstrip('自治州')\n",
    "        if sub_cityname!=cityname and sub_cityname!='':\n",
    "            file_write_obj.writelines(sub_cityname)\n",
    "            file_write_obj.write('\\n')\n",
    "    file_write_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成城市名称停用词\n",
    "citynamesgenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用停用词库，简化字符串，处理同义词\n",
    "def simple(datas):\n",
    "    result=[]\n",
    "    # 添加公司名称停用词\n",
    "    stopwords = readwordslist('./company_stopwords.txt') \n",
    "    # 地域名称通用词\n",
    "    citynames=readwordslist('./citynames.txt')\n",
    "    # 自定义通用词库\n",
    "    permission_words=readwordslist('./addwords.txt')\n",
    "    for data in datas:\n",
    "        # 公司属性 公司性质停用词\n",
    "        for stopword in stopwords:\n",
    "            # 查找不到返回-1 查找到返回\n",
    "            if data.find(stopword)!=-1:\n",
    "                data=re.split(stopword,data)[0]\n",
    "        # 过滤自定义词库\n",
    "        flag=False\n",
    "        for per_word in permission_words:\n",
    "            if data.startswith(per_word):\n",
    "                flag=True\n",
    "        if flag==False:\n",
    "            for cityname in citynames:\n",
    "                # 地名前缀\n",
    "                if data.startswith(cityname):\n",
    "                    data=data.replace(cityname,'')\n",
    "                    break\n",
    "        for cityname in citynames:\n",
    "            # 中插地名 e.g. （北京）\n",
    "            test_chi='（ '+cityname+' ）'\n",
    "            data=data.replace(test_chi,'')\n",
    "            test_eng='( '+cityname+' )'\n",
    "            data=data.replace(test_eng,'')\n",
    "        result.append(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成特征矩阵\n",
    "def get_TFIDF(corpus):\n",
    "    # 将文本中的词语转换为词频矩阵 矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "    vectorizer = CountVectorizer()\n",
    "    # 该类会统计每个词语的tf-idf权值\n",
    "    transformer = TfidfTransformer()\n",
    "    # 第一个fit_transform是计算tf-idf\n",
    "    frequency=vectorizer.fit_transform(corpus)\n",
    "    #第二个fit_transform是将文本转为词频矩阵\n",
    "    tfidf = transformer.fit_transform(frequency)\n",
    "    # 获取词袋模型中的所有词语\n",
    "    word = vectorizer.get_feature_names()\n",
    "    # 将tf-idf矩阵抽取出来，元素w[i][j]表示j词在i类文本中的tf-idf权重\n",
    "    weight = tfidf.toarray()\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取样本 提取公司名称\n",
    "def excel_one_line_to_list():\n",
    "    with open('./data10w.csv','r',encoding='gbk') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        df = [row[32] for row in reader]\n",
    "    # 清理空字符串\n",
    "    df = [string for string in df if string != \"\"]\n",
    "    return df[1:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切割文本 过滤停用词 \n",
    "def split_words(words):\n",
    "    corpus = []  # 语料库 空格连接\n",
    "    # 加载自定义词库\n",
    "    permission_words=readwordslist(\"./addwords.txt\")\n",
    "    for per_word in permission_words:\n",
    "        jieba.add_word(per_word)\n",
    "    for word in words:\n",
    "        # jieba分词\n",
    "        text_cut=jieba.cut(word,cut_all=False)\n",
    "        corpus.append(' '.join(text_cut))  \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件读取完成，有效数据为：  9999\n",
      "！————————当前尝试簇内距离为： 1e-13\n",
      "特征提取结束\n",
      "聚类结束\n"
     ]
    }
   ],
   "source": [
    "eps=[0.0000000000001]\n",
    "# 读取公司名样本\n",
    "data=excel_one_line_to_list()\n",
    "#分词\n",
    "corpus=split_words(data)\n",
    "#停词\n",
    "data_simplified=simple(corpus)\n",
    "# print(data_simplified)\n",
    "# data_simplified=[d.replace(' ','') for d in data_simplified]\n",
    "print(\"文件读取完成，有效数据为： \",len(data))\n",
    "for ep in eps:\n",
    "    print(\"！————————当前尝试簇内距离为：\",ep)\n",
    "    #计时开始\n",
    "    start=time.time()\n",
    "    weight=get_TFIDF(data_simplified)\n",
    "    print(\"特征提取结束\")\n",
    "    #eps为距离阈值ϵ，min_samples为邻域样本数阈值MinPts,X为数据\n",
    "    outcome = DBSCAN(eps=ep, min_samples = 1).fit(weight)\n",
    "    #结果提取\n",
    "    labels=outcome.labels_\n",
    "    print(\"聚类结束\")\n",
    "    #生成可视化表格\n",
    "    count_cluster=Counter(outcome.labels_)\n",
    "    count_company=Counter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_simplified)\n",
    "label=[]\n",
    "frequency=[]\n",
    "companynames=[]\n",
    "sim_company_names=[]\n",
    "for l,f in count_cluster.items():\n",
    "    #统计簇内元素的下标\n",
    "    index=np.where(labels==l)[0]\n",
    "    #统计公司名称\n",
    "    test1=list(set([data[i] for i in index]))\n",
    "    #统计简化公司名称\n",
    "    test2=list(set([data_simplified[i] for i in index]))\n",
    "    for c in test1:\n",
    "        companynames.append(c)\n",
    "        sim_company_names.append(test2)\n",
    "        frequency.append(count_company[c])\n",
    "\n",
    "st = pd.DataFrame()\n",
    "st=pd.DataFrame()#(columns=('聚类名称','公司名称','公司简称','出现频数'))\n",
    "st['公司名称']=companynames\n",
    "st['简化公司名称']=sim_company_names\n",
    "st['频数']=frequency\n",
    "st.to_csv('./dataset/statistics-'+str(ep)+'-0201.csv',encoding='utf_8_sig',index=False)\n",
    "# 生成公司聚类标签数据\n",
    "df = pd.DataFrame()\n",
    "df['公司名称']=data\n",
    "df['简化公司名称']=data_simplified\n",
    "df['标签'] = labels\n",
    "df.to_csv('./dataset/cluster-'+str(ep)+'-0201.csv',encoding='utf_8_sig',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件读取完成，有效数据为：  75353\n",
      "！————————当前尝试簇内距离为： 0.001\n",
      "！————————总结\n",
      "有效经纪公司总数： 75353\n",
      "聚类后有效公司数：  1569\n",
      "关键词总数:  (75353, 1049)\n",
      "总耗时：  10429.783033847809 秒\n",
      "共耗时：  2.8971619538466133 小时\n",
      "！————————当前尝试簇内距离为： 0.01\n",
      "！————————总结\n",
      "有效经纪公司总数： 75353\n",
      "聚类后有效公司数：  1569\n",
      "关键词总数:  (75353, 1049)\n",
      "总耗时：  10563.932601928711 秒\n",
      "共耗时：  2.9344257227579753 小时\n",
      "！————————当前尝试簇内距离为： 0.1\n",
      "！————————总结\n",
      "有效经纪公司总数： 75353\n",
      "聚类后有效公司数：  1569\n",
      "关键词总数:  (75353, 1049)\n",
      "总耗时：  10444.105413198471 秒\n",
      "共耗时：  2.901140392555131 小时\n",
      "！————————当前尝试簇内距离为： 1\n",
      "！————————总结\n",
      "有效经纪公司总数： 75353\n",
      "聚类后有效公司数：  1569\n",
      "关键词总数:  (75353, 1049)\n",
      "总耗时：  17891.7833340168 秒\n",
      "共耗时：  4.9699398150046665 小时\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    label=[]\n",
    "    frequency=[]\n",
    "    companynames=[]\n",
    "    sim_company_names=[]\n",
    "    for l,f in count_cluster.items():\n",
    "        #统计簇内元素的下标\n",
    "        index=np.where(labels==l)[0]\n",
    "        #统计公司名称\n",
    "        test1=list(set([data[i] for i in index]))\n",
    "        #统计简化公司名称\n",
    "        test2=list(set([data_simplified[i] for i in index]))\n",
    "        for c in test1:\n",
    "            companynames.append(c)\n",
    "            sim_company_names.append(test2)\n",
    "            frequency.append(count_company[c])\n",
    "\n",
    "    st = pd.DataFrame()\n",
    "    st=pd.DataFrame()#(columns=('聚类名称','公司名称','公司简称','出现频数'))\n",
    "    st['公司名称']=companynames\n",
    "    st['简化公司名称']=sim_company_names\n",
    "    st['频数']=frequency\n",
    "    st.to_csv('./dataset/statistics-'+str(ep)+'.csv',encoding='utf_8_sig',index=False)\n",
    "    # 生成公司聚类标签数据\n",
    "    df = pd.DataFrame()\n",
    "    df['公司名称']=data\n",
    "    df['简化公司名称']=data_simplified\n",
    "    df['标签'] = labels\n",
    "    df.to_csv('./dataset/cluster-'+str(ep)+'.csv',encoding='utf_8_sig',index=False)\n",
    "    print('文本生成结束')\n",
    "    print(\"！————————总结\")\n",
    "    print(\"有效经纪公司总数：\",len(data))\n",
    "    print('聚类后有效公司数： ',len(companynames))\n",
    "    print(\"关键词总数: \",weight.shape)\n",
    "    total=(time.time())-start\n",
    "    print(\"总耗时： \",total,\"秒\")\n",
    "    print('共耗时： ',total/3600,'小时')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps=[0.001,0.01,0.1,1]\n",
    "# 读取公司名样本\n",
    "data=excel_one_line_to_list()\n",
    "print(\"文件读取完成，有效数据为： \",len(data))\n",
    "print(\"！————————当前尝试簇内距离为：\",ep)\n",
    "#计时开始\n",
    "start=time.time()\n",
    "#停词\n",
    "data_simplified=simple(data)\n",
    "#     print(\"停词结束\")\n",
    "# 特征提取 计算TF-IDF\n",
    "weight=get_TFIDF(data_simplified)\n",
    "#     print(\"特征提取结束\")\n",
    "#eps为距离阈值ϵ，min_samples为邻域样本数阈值MinPts,X为数据\n",
    "outcome = DBSCAN(eps=ep, min_samples = 1).fit(weight)\n",
    "#结果提取\n",
    "labels=outcome.labels_\n",
    "#     print(\"聚类结束\")\n",
    "#生成可视化表格\n",
    "count_cluster=Counter(outcome.labels_)\n",
    "count_company=Counter(data)\n",
    "label=[]\n",
    "frequency=[]\n",
    "companynames=[]\n",
    "sim_company_names=[]\n",
    "for l,f in count_cluster.items():\n",
    "    #统计簇内元素的下标\n",
    "    index=np.where(labels==l)[0]\n",
    "    #统计公司名称\n",
    "    test1=list(set([data[i] for i in index]))\n",
    "    #统计简化公司名称\n",
    "    test2=list(set([data_simplified[i] for i in index]))\n",
    "    for c in test1:\n",
    "        companynames.append(c)\n",
    "        sim_company_names.append(test2)\n",
    "        frequency.append(count_company[c])\n",
    "\n",
    "st = pd.DataFrame()\n",
    "st=pd.DataFrame()#(columns=('聚类名称','公司名称','公司简称','出现频数'))\n",
    "st['公司名称']=companynames\n",
    "st['简化公司名称']=sim_company_names\n",
    "st['频数']=frequency\n",
    "st.to_csv('./dataset/statistics-'+str(ep)+'.csv',encoding='utf_8_sig',index=False)\n",
    "# 生成公司聚类标签数据\n",
    "df = pd.DataFrame()\n",
    "df['公司名称']=data\n",
    "df['简化公司名称']=data_simplified\n",
    "df['标签'] = labels\n",
    "df.to_csv('./dataset/cluster-'+str(ep)+'.csv',encoding='utf_8_sig',index=False)\n",
    "#     print('文本生成结束')\n",
    "print(\"！————————总结\")\n",
    "print(\"有效经纪公司总数：\",len(data))\n",
    "print('聚类后有效公司数： ',len(companynames))\n",
    "print(\"关键词总数: \",weight.shape)\n",
    "total=(time.time())-start\n",
    "print(\"总耗时： \",total,\"秒\")\n",
    "print('共耗时： ',total/3600,'小时')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
